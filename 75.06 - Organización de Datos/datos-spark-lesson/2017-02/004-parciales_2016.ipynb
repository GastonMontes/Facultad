{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcial 2016 2do Cuatrimestre, Ejercicio 2 \n",
    "\n",
    "En este ejercicio queremos programar un sistema que recomiende\n",
    "textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto\n",
    "es un string de longitud variable. \n",
    "\n",
    "Además contamos con un RDD que\n",
    "indica qué términos le gustan o no a cada usuario de la forma (userId,\n",
    "término, score) por ejemplo (23, “calesita”, -2). \n",
    "\n",
    "Se pide programar en Spark un programa que calcule el score total de cada documento para cada usuario generando un RDD de la forma (userId, docId, score) en donde el score es simplemente la suma de los scores del usuario para\n",
    "los términos que aparecen en el documento. \n",
    "\n",
    "Puede haber términos en los documentos para los cuales no exista score de algunos usuarios, en\n",
    "estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    (1, 'pablo honey'),\n",
    "    (2, 'the bends'),\n",
    "    (3, 'ok computer'),\n",
    "    (4, 'kid a'),\n",
    "    (5, 'amnesiac'),\n",
    "    (6, 'hail to the thief'),\n",
    "    (7, 'in rainbows'),\n",
    "    (8, 'the king of limbs'),\n",
    "    (9, 'a moon shaped pool')\n",
    "]\n",
    "\n",
    "scores = [\n",
    "    ('thom', 'pablo', 1),\n",
    "    ('thom', 'honey', 1),\n",
    "    ('martin', 'pablo', -1),\n",
    "    ('martin', 'honey', -1),\n",
    "    ('martin', 'ok', 30),\n",
    "    ('martin', 'computer', 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documentsRDD = sc.parallelize(documents)\n",
    "scoresRDD = sc.parallelize(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pablo', 1),\n",
       " ('honey', 1),\n",
       " ('the', 2),\n",
       " ('bends', 2),\n",
       " ('ok', 3),\n",
       " ('computer', 3),\n",
       " ('kid', 4),\n",
       " ('a', 4),\n",
       " ('amnesiac', 5),\n",
       " ('hail', 6),\n",
       " ('to', 6),\n",
       " ('the', 6),\n",
       " ('thief', 6),\n",
       " ('in', 7),\n",
       " ('rainbows', 7),\n",
       " ('the', 8),\n",
       " ('king', 8),\n",
       " ('of', 8),\n",
       " ('limbs', 8),\n",
       " ('a', 9),\n",
       " ('moon', 9),\n",
       " ('shaped', 9),\n",
       " ('pool', 9)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generamos algo del tipo (word, docId) donde word sera nuestra key\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pablo', ('thom', 1)),\n",
       " ('honey', ('thom', 1)),\n",
       " ('pablo', ('martin', -1)),\n",
       " ('honey', ('martin', -1)),\n",
       " ('ok', ('martin', 30)),\n",
       " ('computer', ('martin', 30))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llevamos scores a una representacion que nos permita unir la informacion\n",
    "scoresRDDForJoin = scoresRDD.map(lambda a: (a[1],(a[0],a[2])))\n",
    "scoresRDDForJoin.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('honey', (1, ('thom', 1))),\n",
       " ('honey', (1, ('martin', -1))),\n",
       " ('computer', (3, ('martin', 30))),\n",
       " ('ok', (3, ('martin', 30))),\n",
       " ('pablo', (1, ('thom', 1))),\n",
       " ('pablo', (1, ('martin', -1)))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 'thom'), 1),\n",
       " ((1, 'martin'), -1),\n",
       " ((3, 'martin'), 30),\n",
       " ((3, 'martin'), 30),\n",
       " ((1, 'thom'), 1),\n",
       " ((1, 'martin'), -1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para poder realizar una acumulacion debemos llevar la informacion a la representacion (docId, userId, score) \n",
    "# y luego realizar una acumulacion de scores\n",
    "# ignorando el score\n",
    "\n",
    "# notese que el K es docId, userId y el V es el score que aporta el termino\n",
    "\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 'martin'), 60), ((1, 'thom'), 2), ((1, 'martin'), -2)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acumulamos haciendo reduce\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .reduceByKey(lambda a,b: a + b)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'martin', 60), (1, 'thom', 2), (1, 'martin', -2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llevamos a la representacion pedida\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .reduceByKey(lambda a,b: a + b)\\\n",
    "    .map(lambda a: (a[0][0], a[0][1], a[1]))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcial 2016 2do Cuatrimestre, Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contamos con un cluster que tiene 4 computadoras. \n",
    "\n",
    "Queremos aprovechar el paralelismo del cluster para calcular los números primos entre 2 y 20.000.000. Para esto usaremos el conocido algoritmo de la\n",
    "criba de Eratóstenes. Por ejemplo si empezamos con una lista de tipo (2,3,4,5,6,7,8...) en un primer paso eliminamos todos los que son\n",
    "mayores a 2 y divisibles por 2 y nos queda (2,3,5,7,9,11,13…) luego\n",
    "eliminamos todos los mayores a 3 divisibles por 3 y nos queda\n",
    "(2,3,5,7,11,13….etc) luego todos los divisibles por 5 y así\n",
    "sucesivamente. \n",
    "\n",
    "El resultado final es una lista de números que son\n",
    "primos. \n",
    "\n",
    "Programar este programa usando PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# criterio\n",
    "# En primer lugar hay que crear un RDD con todos los números y hacer un parallelize con 4 particiones. \n",
    "# Luego la resolución pasa por un ciclo en el cual en cada paso del ciclo se obtenga \n",
    "# como pivote el mínimo número del RDD que sea mayor al número\n",
    "# usado como pivote anteriormente, luego simplemente hay que \n",
    "# filtrar el RDD eliminando los números que son múltiplos del pivote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificacion de multiplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_not_multiple(pivot, value):\n",
    "        if pivot == value:\n",
    "            return True\n",
    "        \n",
    "        if (value % pivot) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_not_multiple(3, 1)\n",
    "assert is_not_multiple(3, 2)\n",
    "assert is_not_multiple(3, 3)\n",
    "assert is_not_multiple(3, 4)\n",
    "assert is_not_multiple(3, 5)\n",
    "assert not is_not_multiple(3, 6)\n",
    "assert is_not_multiple(3, 7)\n",
    "assert is_not_multiple(3, 8)\n",
    "assert not is_not_multiple(3, 9)\n",
    "assert is_not_multiple(3, 10)\n",
    "assert is_not_multiple(3, 11)\n",
    "assert not is_not_multiple(3, 12)\n",
    "\n",
    "assert is_not_multiple(2, 7)\n",
    "assert is_not_multiple(3, 7)\n",
    "assert is_not_multiple(5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacemos un caso de juguete de 2 a 20\n",
    "numbers = sc.parallelize(range(2,21), 4)\n",
    "pivot = 2\n",
    "\n",
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 7, 11, 13, 17, 19]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.filter(lambda a: is_not_multiple(2, a))\\ # Filtro (o sea me quedo) con los que no son multiplos de 2.\n",
    "       .filter(lambda a: is_not_multiple(3, a))\\ # Filtro (o sea me quedo) con los que no son multiplos de 3.\n",
    "       .filter(lambda a: is_not_multiple(5, a)).collect() # Filtro (o sea me quedo) con los que no son multiplos de 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos un caso de juguete de 2 a 2000\n",
    "numbers = sc.parallelize(range(2,2000), 4)\n",
    "\n",
    "pivot = 2\n",
    "\n",
    "while ((pivot * pivot) <= 2000):\n",
    "    new_pivot = numbers.filter(lambda a: a > pivot).reduce(lambda a, b: a if a < b else b)\n",
    "    numbers = numbers.filter(lambda a: is_not_multiple(pivot, a)).cache()\n",
    "    pivot = new_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97,\n",
       " 101,\n",
       " 103,\n",
       " 107,\n",
       " 109,\n",
       " 113,\n",
       " 127,\n",
       " 131,\n",
       " 137,\n",
       " 139,\n",
       " 149,\n",
       " 151,\n",
       " 157,\n",
       " 163,\n",
       " 167,\n",
       " 173,\n",
       " 179,\n",
       " 181,\n",
       " 191,\n",
       " 193,\n",
       " 197,\n",
       " 199,\n",
       " 211,\n",
       " 223,\n",
       " 227,\n",
       " 229,\n",
       " 233,\n",
       " 239,\n",
       " 241,\n",
       " 251,\n",
       " 257,\n",
       " 263,\n",
       " 269,\n",
       " 271,\n",
       " 277,\n",
       " 281,\n",
       " 283,\n",
       " 293,\n",
       " 307,\n",
       " 311,\n",
       " 313,\n",
       " 317,\n",
       " 331,\n",
       " 337,\n",
       " 347,\n",
       " 349,\n",
       " 353,\n",
       " 359,\n",
       " 367,\n",
       " 373,\n",
       " 379,\n",
       " 383,\n",
       " 389,\n",
       " 397,\n",
       " 401,\n",
       " 409,\n",
       " 419,\n",
       " 421,\n",
       " 431,\n",
       " 433,\n",
       " 439,\n",
       " 443,\n",
       " 449,\n",
       " 457,\n",
       " 461,\n",
       " 463,\n",
       " 467,\n",
       " 479,\n",
       " 487,\n",
       " 491,\n",
       " 499,\n",
       " 503,\n",
       " 509,\n",
       " 521,\n",
       " 523,\n",
       " 541,\n",
       " 547,\n",
       " 557,\n",
       " 563,\n",
       " 569,\n",
       " 571,\n",
       " 577,\n",
       " 587,\n",
       " 593,\n",
       " 599,\n",
       " 601,\n",
       " 607,\n",
       " 613,\n",
       " 617,\n",
       " 619,\n",
       " 631,\n",
       " 641,\n",
       " 643,\n",
       " 647,\n",
       " 653,\n",
       " 659,\n",
       " 661,\n",
       " 673,\n",
       " 677,\n",
       " 683,\n",
       " 691,\n",
       " 701,\n",
       " 709,\n",
       " 719,\n",
       " 727,\n",
       " 733,\n",
       " 739,\n",
       " 743,\n",
       " 751,\n",
       " 757,\n",
       " 761,\n",
       " 769,\n",
       " 773,\n",
       " 787,\n",
       " 797,\n",
       " 809,\n",
       " 811,\n",
       " 821,\n",
       " 823,\n",
       " 827,\n",
       " 829,\n",
       " 839,\n",
       " 853,\n",
       " 857,\n",
       " 859,\n",
       " 863,\n",
       " 877,\n",
       " 881,\n",
       " 883,\n",
       " 887,\n",
       " 907,\n",
       " 911,\n",
       " 919,\n",
       " 929,\n",
       " 937,\n",
       " 941,\n",
       " 947,\n",
       " 953,\n",
       " 967,\n",
       " 971,\n",
       " 977,\n",
       " 983,\n",
       " 991,\n",
       " 997,\n",
       " 1009,\n",
       " 1013,\n",
       " 1019,\n",
       " 1021,\n",
       " 1031,\n",
       " 1033,\n",
       " 1039,\n",
       " 1049,\n",
       " 1051,\n",
       " 1061,\n",
       " 1063,\n",
       " 1069,\n",
       " 1087,\n",
       " 1091,\n",
       " 1093,\n",
       " 1097,\n",
       " 1103,\n",
       " 1109,\n",
       " 1117,\n",
       " 1123,\n",
       " 1129,\n",
       " 1151,\n",
       " 1153,\n",
       " 1163,\n",
       " 1171,\n",
       " 1181,\n",
       " 1187,\n",
       " 1193,\n",
       " 1201,\n",
       " 1213,\n",
       " 1217,\n",
       " 1223,\n",
       " 1229,\n",
       " 1231,\n",
       " 1237,\n",
       " 1249,\n",
       " 1259,\n",
       " 1277,\n",
       " 1279,\n",
       " 1283,\n",
       " 1289,\n",
       " 1291,\n",
       " 1297,\n",
       " 1301,\n",
       " 1303,\n",
       " 1307,\n",
       " 1319,\n",
       " 1321,\n",
       " 1327,\n",
       " 1361,\n",
       " 1367,\n",
       " 1373,\n",
       " 1381,\n",
       " 1399,\n",
       " 1409,\n",
       " 1423,\n",
       " 1427,\n",
       " 1429,\n",
       " 1433,\n",
       " 1439,\n",
       " 1447,\n",
       " 1451,\n",
       " 1453,\n",
       " 1459,\n",
       " 1471,\n",
       " 1481,\n",
       " 1483,\n",
       " 1487,\n",
       " 1489,\n",
       " 1493,\n",
       " 1499,\n",
       " 1511,\n",
       " 1523,\n",
       " 1531,\n",
       " 1543,\n",
       " 1549,\n",
       " 1553,\n",
       " 1559,\n",
       " 1567,\n",
       " 1571,\n",
       " 1579,\n",
       " 1583,\n",
       " 1597,\n",
       " 1601,\n",
       " 1607,\n",
       " 1609,\n",
       " 1613,\n",
       " 1619,\n",
       " 1621,\n",
       " 1627,\n",
       " 1637,\n",
       " 1657,\n",
       " 1663,\n",
       " 1667,\n",
       " 1669,\n",
       " 1693,\n",
       " 1697,\n",
       " 1699,\n",
       " 1709,\n",
       " 1721,\n",
       " 1723,\n",
       " 1733,\n",
       " 1741,\n",
       " 1747,\n",
       " 1753,\n",
       " 1759,\n",
       " 1777,\n",
       " 1783,\n",
       " 1787,\n",
       " 1789,\n",
       " 1801,\n",
       " 1811,\n",
       " 1823,\n",
       " 1831,\n",
       " 1847,\n",
       " 1861,\n",
       " 1867,\n",
       " 1871,\n",
       " 1873,\n",
       " 1877,\n",
       " 1879,\n",
       " 1889,\n",
       " 1901,\n",
       " 1907,\n",
       " 1913,\n",
       " 1931,\n",
       " 1933,\n",
       " 1949,\n",
       " 1951,\n",
       " 1973,\n",
       " 1979,\n",
       " 1987,\n",
       " 1993,\n",
       " 1997,\n",
       " 1999]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
